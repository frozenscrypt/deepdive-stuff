{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24b2a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "\n",
    "from keras.models import *\n",
    "import keras.backend as K\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Dense, Lambda\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def target_category_loss(x, category_index, nb_classes):\n",
    "    return tf.multiply(x, K.one_hot([category_index], nb_classes))\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
    "\n",
    "def target_category_loss_output_shape(input_shape):\n",
    "    return input_shape\n",
    "\n",
    "def grad_cam(input_model, test_img_path, category_index, output_path):\n",
    "    #Read original image\n",
    "    original_img = cv2.imread(test_img_path, 1)\n",
    "\n",
    "    #Resize image to pass through the model (not necessary)\n",
    "    img = cv2.resize(original_img,(150,150))\n",
    "    width, height, _ = img.shape\n",
    "\n",
    "    #Expand dims to create a batch of size 1\n",
    "    batch_img = np.expand_dims(img,axis=0)\n",
    "\n",
    "    nb_classes = 2\n",
    "    target_layer = lambda x: target_category_loss(x, category_index, nb_classes)\n",
    "    model.add(Lambda(target_layer,\n",
    "                     output_shape = target_category_loss_output_shape))\n",
    "\n",
    "    loss = K.sum(model.layers[-1].output)\n",
    "    conv_output =  model.layers[-4].output\n",
    "    print(conv_output.shape)\n",
    "    grads = normalize(K.gradients(loss, conv_output)[0])\n",
    "    gradient_function = K.function([model.layers[0].input], [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([batch_img])\n",
    "    print(output.shape,grads_val.shape)\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "\n",
    "    weights = np.mean(grads_val, axis = (0, 1))\n",
    "    cam = np.ones(output.shape[0 : 2], dtype = np.float32)\n",
    "\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * output[:, :, i]\n",
    "\n",
    "    cam = cv2.resize(cam, (150, 150))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    heatmap = cam / np.max(cam)\n",
    "\n",
    "    img -= np.min(img)\n",
    "    img = np.minimum(img, 255)\n",
    "\n",
    "    cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "    cam = np.float32(cam) + np.float32(img)\n",
    "    cam = 255 * cam / np.max(cam)\n",
    "    cam = np.uint8(cam)\n",
    "    cv2.imwrite(output_path,cam)\n",
    "    return cam, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9abeace6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 7, 7, 64)\n",
      "(1, 7, 7, 64) (1, 7, 7, 64)\n"
     ]
    }
   ],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "    \n",
    "#Helper functions to define model\n",
    "def global_average_pooling(x):\n",
    "    return K.mean(x, axis = (1, 2))\n",
    "\n",
    "def global_average_pooling_shape(input_shape):\n",
    "    return input_shape[0:2]\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "#Defining Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Lambda(global_average_pooling, \n",
    "              output_shape=global_average_pooling_shape))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Since we have a trained model, load the model weights\n",
    "model_path = 'weights/weights.50-0.43.h5' \n",
    "model.load_weights(model_path)\n",
    "\n",
    "#Dog CAM\n",
    "path = 'data/train/dogs'\n",
    "images = os.listdir(path)\n",
    "index = np.random.randint(0,len(images))\n",
    "img_path = os.path.join(path,images[index])\n",
    "\n",
    "cam,heatmap = grad_cam(model,img_path,1,'GRADCAM/dog.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
